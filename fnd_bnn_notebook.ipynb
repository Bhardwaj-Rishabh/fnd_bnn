{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "from edward.models import Normal\n",
    "from edward.models import Beta\n",
    "from edward.models import Bernoulli, MultivariateNormalTriL\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from getEmbeddings import getEmbeddings\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot.plotters as skplt\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_DIM = 300\n",
    "CLASS_NUM = 2\n",
    "LEARN_RATE = 0.0001\n",
    "TRAIN_STEP = 20000\n",
    "tensorflow_tmp = \"tmp_tensorflow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 16608\n",
    "D = IN_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def data():\n",
    "    # Get the training and testing data from getEmbeddings\n",
    "    # Read the Doc2Vec data\n",
    "    train_data = np.load('../Data/xtr.npy')\n",
    "    eval_data = np.load('../Data/xte.npy')\n",
    "    train_labels = np.load('../Data/ytr.npy')\n",
    "    eval_labels = np.load('../Data/yte.npy')\n",
    "    train_labels = train_labels.reshape((-1, 1)).astype(np.int32)\n",
    "\n",
    "    return train_data, train_labels.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def neural_network(X):\n",
    "    h = tf.nn.relu(tf.matmul(X, W_0) + b_0)\n",
    "    h = tf.nn.relu(tf.matmul(h, W_1) + b_1)\n",
    "    h = tf.nn.relu(tf.matmul(h, W_2) + b_2)\n",
    "    h = tf.nn.relu(tf.matmul(h, W_3) + b_3)\n",
    "    return tf.reshape(h, [-1])\n",
    "\n",
    "ed.set_seed(42)\n",
    "'''\n",
    "def neural_network(X):\n",
    "    h = tf.tanh(tf.matmul(X, W_0) + b_0)\n",
    "    h = tf.tanh(tf.matmul(h, W_1) + b_1)\n",
    "    h = tf.tanh(tf.matmul(h, W_2) + b_2)\n",
    "    h = tf.tanh(tf.matmul(h, W_3) + b_3)\n",
    "    return tf.reshape(h, [-1])\n",
    "\n",
    "ed.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"model\"):\n",
    "    W_0 = Normal(loc=tf.zeros([D, 300]), scale=tf.ones([D, 300]),\n",
    "                 name=\"W_0\")\n",
    "    W_1 = Normal(loc=tf.zeros([300, 300]), scale=tf.ones([300, 300]), name=\"W_1\")\n",
    "    W_2 = Normal(loc=tf.zeros([300, 300]), scale=tf.ones([300, 300]), name=\"W_2\")\n",
    "    W_3 = Normal(loc=tf.zeros([300, 1]), scale=tf.ones([300, 1]), name=\"W_3\")\n",
    "    b_0 = Normal(loc=tf.zeros(300), scale=tf.ones(300), name=\"b_0\")\n",
    "    b_1 = Normal(loc=tf.zeros(300), scale=tf.ones(300), name=\"b_1\")\n",
    "    b_2 = Normal(loc=tf.zeros(300), scale=tf.ones(300), name=\"b_2\")\n",
    "    b_3 = Normal(loc=tf.ones(1), scale=tf.ones(1), name=\"b_3\")  \n",
    "    X = tf.placeholder(tf.float32, [N, D], name=\"X\")\n",
    "    #y = Normal(loc=neural_network(X), scale=0.1 * tf.ones(N), name=\"y\")\n",
    "    y = Bernoulli(logits=neural_network(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16608, 300)\n",
      "(16608,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE\n",
    "with tf.variable_scope(\"posterior\"):\n",
    "    with tf.variable_scope(\"qW_0\"):\n",
    "      loc = tf.get_variable(\"loc\", [D, 300])\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [D, 300]))\n",
    "      qW_0 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qW_1\"):\n",
    "      loc = tf.get_variable(\"loc\", [300, 300])\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [300, 300]))\n",
    "      qW_1 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qW_2\"):\n",
    "      loc = tf.get_variable(\"loc\", [300, 300])\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [300, 300]))\n",
    "      qW_2 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qW_3\"):\n",
    "      loc = tf.get_variable(\"loc\", [300, 1])\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [300, 1]))\n",
    "      qW_3 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qb_0\"):\n",
    "      loc = tf.get_variable(\"loc\", [300])\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [300]))\n",
    "      qb_0 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qb_1\"):\n",
    "      loc = tf.get_variable(\"loc\", [300])\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [300]))\n",
    "      qb_1 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qb_2\"):\n",
    "      loc = tf.get_variable(\"loc\", [300])\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [300]))\n",
    "      qb_2 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qb_3\"):\n",
    "      loc = tf.get_variable(\"loc\", [1])\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [1]))\n",
    "      qb_3 = Normal(loc=loc, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nzero_initializer = tf.constant_initializer(value=0.0)\\nones_initializer = tf.constant_initializer(value=1.0)\\nwith tf.variable_scope(\"posterior\"):\\n    with tf.variable_scope(\"qW_0\"):\\n      loc = tf.get_variable(\"loc\", [D, 1000], initializer=zero_initializer)\\n      scale = tf.nn.softplus(tf.get_variable(\"scale\", [D, 1000], initializer=ones_initializer))\\n      qW_0 = Normal(loc=loc, scale=scale)\\n    with tf.variable_scope(\"qW_1\"):\\n      loc = tf.get_variable(\"loc\", [1000, 500], initializer=zero_initializer)\\n      scale = tf.nn.softplus(tf.get_variable(\"scale\", [1000, 500], initializer=ones_initializer))\\n      qW_1 = Normal(loc=loc, scale=scale)\\n    with tf.variable_scope(\"qW_2\"):\\n      loc = tf.get_variable(\"loc\", [500, 300], initializer=zero_initializer)\\n      scale = tf.nn.softplus(tf.get_variable(\"scale\", [500, 300], initializer=ones_initializer))\\n      qW_2 = Normal(loc=loc, scale=scale)\\n    with tf.variable_scope(\"qW_3\"):\\n      loc = tf.get_variable(\"loc\", [300, 1], initializer=zero_initializer)\\n      scale = tf.nn.softplus(tf.get_variable(\"scale\", [300, 1], initializer=ones_initializer))\\n      qW_3 = Normal(loc=loc, scale=scale)\\n    with tf.variable_scope(\"qb_0\"):\\n      loc = tf.get_variable(\"loc\", [1000], initializer=zero_initializer)\\n      scale = tf.nn.softplus(tf.get_variable(\"scale\", [1000], initializer=ones_initializer))\\n      qb_0 = Normal(loc=loc, scale=scale)\\n    with tf.variable_scope(\"qb_1\"):\\n      loc = tf.get_variable(\"loc\", [500], initializer=zero_initializer)\\n      scale = tf.nn.softplus(tf.get_variable(\"scale\", [500], initializer=ones_initializer))\\n      qb_1 = Normal(loc=loc, scale=scale)\\n    with tf.variable_scope(\"qb_2\"):\\n      loc = tf.get_variable(\"loc\", [300], initializer=zero_initializer)\\n      scale = tf.nn.softplus(tf.get_variable(\"scale\", [300], initializer=ones_initializer))\\n      qb_2 = Normal(loc=loc, scale=scale)\\n    with tf.variable_scope(\"qb_3\"):\\n      loc = tf.get_variable(\"loc\", [1], initializer=zero_initializer)\\n      scale = tf.nn.softplus(tf.get_variable(\"scale\", [1], initializer=ones_initializer))\\n      qb_3 = Normal(loc=loc, scale=scale)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "zero_initializer = tf.constant_initializer(value=0.0)\n",
    "ones_initializer = tf.constant_initializer(value=1.0)\n",
    "with tf.variable_scope(\"posterior\"):\n",
    "    with tf.variable_scope(\"qW_0\"):\n",
    "      loc = tf.get_variable(\"loc\", [D, 1000], initializer=zero_initializer)\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [D, 1000], initializer=ones_initializer))\n",
    "      qW_0 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qW_1\"):\n",
    "      loc = tf.get_variable(\"loc\", [1000, 500], initializer=zero_initializer)\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [1000, 500], initializer=ones_initializer))\n",
    "      qW_1 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qW_2\"):\n",
    "      loc = tf.get_variable(\"loc\", [500, 300], initializer=zero_initializer)\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [500, 300], initializer=ones_initializer))\n",
    "      qW_2 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qW_3\"):\n",
    "      loc = tf.get_variable(\"loc\", [300, 1], initializer=zero_initializer)\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [300, 1], initializer=ones_initializer))\n",
    "      qW_3 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qb_0\"):\n",
    "      loc = tf.get_variable(\"loc\", [1000], initializer=zero_initializer)\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [1000], initializer=ones_initializer))\n",
    "      qb_0 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qb_1\"):\n",
    "      loc = tf.get_variable(\"loc\", [500], initializer=zero_initializer)\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [500], initializer=ones_initializer))\n",
    "      qb_1 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qb_2\"):\n",
    "      loc = tf.get_variable(\"loc\", [300], initializer=zero_initializer)\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [300], initializer=ones_initializer))\n",
    "      qb_2 = Normal(loc=loc, scale=scale)\n",
    "    with tf.variable_scope(\"qb_3\"):\n",
    "      loc = tf.get_variable(\"loc\", [1], initializer=zero_initializer)\n",
    "      scale = tf.nn.softplus(tf.get_variable(\"scale\", [1], initializer=ones_initializer))\n",
    "      qb_3 = Normal(loc=loc, scale=scale)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcsbhr\\AppData\\Local\\Continuum\\anaconda3\\envs\\edward_env\\lib\\site-packages\\edward\\util\\random_variables.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  not np.issubdtype(value.dtype, np.float) and \\\n",
      "C:\\Users\\dcsbhr\\AppData\\Local\\Continuum\\anaconda3\\envs\\edward_env\\lib\\site-packages\\edward\\util\\random_variables.py:53: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  not np.issubdtype(value.dtype, np.int) and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 165s | Loss: 19070.117\n"
     ]
    }
   ],
   "source": [
    "#lets do inference\n",
    "inference = ed.KLqp({W_0: qW_0, b_0: qb_0,\n",
    "                   W_1: qW_1, b_1: qb_1,\n",
    "                   W_2: qW_2, b_2: qb_2,\n",
    "                   W_3: qW_3, b_3: qb_3}, data={X: X_train, y: y_train})\n",
    "inference.run(logdir='log', n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14757948"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.evaluate('categorical_accuracy', data={y: y_train, X: X_train})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:edward_env]",
   "language": "python",
   "name": "conda-env-edward_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
